{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlx.core as mx\n",
    "import mlx.nn as nn\n",
    "\n",
    "import mlx.optimizers as optim\n",
    "from mlx.utils import tree_map\n",
    "from functools import partial\n",
    "import mlx.core as mx\n",
    "import mlx.nn as nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gat_layer(nn.Module):\n",
    "    def __init__(self, dim_proj: int, num_att_heads: int): \n",
    "        super().__init__()\n",
    "\n",
    "        self.dim_proj = dim_proj\n",
    "        self.num_att_heads = num_att_heads\n",
    "\n",
    "        self.source_scores = mx.array([1, num_att_heads, dim_proj]) \n",
    "        self.target_scores = mx.array([1, num_att_heads, dim_proj]) \n",
    "\n",
    "    def __call__(self, nodes_proj, adjacency_matrix):\n",
    "\n",
    "        node_proj = node_proj.reshape([-1, self.num_att_heads, self.dim_proj])\n",
    "    \n",
    "        source_scores = (node_proj * self.source_scores).sum(dim=-1)\n",
    "        target_scores = (node_proj * self.target_scores).sum(dim=-1)\n",
    "\n",
    "        neighborhood_indices = np.nonzero(adjacency_matrix) \n",
    "        masked_target_scores = mx.take(target_scores, neighborhood_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class gat(nn.Module):\n",
    "    def __init__(self, num_nodes: int, dim_embed: int, dim_proj: int, num_att_heads: int, num_layers: int, skip_connections: bool, num_out_layers: int): \n",
    "        super().__init__()\n",
    "        \n",
    "        total_att_size = dim_proj * num_att_heads;\n",
    "\n",
    "        gat_layer = gat_layer(total_att_size)\n",
    "\n",
    "        self.embed_proj = mx.linear(dim_embed, total_att_size)\n",
    "        self.gat_layers = mx.Sequential([gat_layer] * num_layers)\n",
    "        self.out_layers = mx.Sequential([mx.Linear(total_att_size, total_att_size)] * num_out_layers + [mx.Linear(total_att_size, 7)])\n",
    "\n",
    "    def __call__(self, node_embeddings, adjacency_matrix):\n",
    "        assert node_embeddings.shape[1] == self.dim_embed, f'Incorrect node embedding size'\n",
    "\n",
    "        node_proj = self.embed_proj(node_embeddings);\n",
    "\n",
    "        for layer in self.gat_layers:\n",
    "            new_node_proj = layer(node_proj)\n",
    "            if (self.skip_connections):\n",
    "                new_node_proj += node_proj;\n",
    "            node_proj = new_node_proj\n",
    "\n",
    "        for layer in self.out_layers:\n",
    "            node_embeddings = nn.leaky_relu(mx.layer(node_embeddings), .02)\n",
    "\n",
    "        return mx.softmax(node_embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
